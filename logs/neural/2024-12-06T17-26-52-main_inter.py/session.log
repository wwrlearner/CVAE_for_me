GMVAE (
  (x_encoder): EncoderRNN(
    (input_dropout): Dropout(p=0, inplace=False)
    (rnn): GRU(100, 64, batch_first=True, dropout=0.3, bidirectional=True)
  ), parameters=63744
  (decoder): DecoderRNN(
    (input_dropout): Dropout(p=0.3, inplace=False)
    (rnn): GRU(64, 64, batch_first=True, dropout=0.3)
    (project): Linear(in_features=64, out_features=2, bias=True)
  ), parameters=25090
  (q_y_mean): Linear(in_features=128, out_features=10, bias=True), parameters=1290
  (q_y_logvar): Linear(in_features=128, out_features=10, bias=True), parameters=1290
  (post_c): Sequential (
    (0): Linear(in_features=128, out_features=128, bias=True), weights=((128, 128), (128,)), parameters=16512
    (1): ReLU(), weights=(), parameters=0
    (2): Linear(in_features=128, out_features=40, bias=True), weights=((40, 128), (40,)), parameters=5160
  ) Total Parameters=21672, parameters=21672
  (dec_init_connector): LinearConnector(
    (linear): Linear(in_features=10, out_features=64, bias=False)
  ), parameters=640
  (firing_rate): Linear(in_features=2, out_features=100, bias=True), parameters=300
  (cat_connector): GumbelConnector(), parameters=0
  (mse_loss): TimeSeriesLossMSE(
    (mse_loss): MSELoss()
  ), parameters=0
  (cat_kl_loss): CatKLLoss(), parameters=0
) Total Parameters=114026
**** Training Begins ****
**** Epoch 0/50 ****
Flush previous valid loss
Recovering the learning rate to 0.001
Load previous best model
500/2000-(0.000): Train nll 14346.377 PPL inf agg_ckl 0.310 mi 0.001 zkl 0.059 dispersion 4.510 real_zkl 4.569 real_ckl 0.311 elbo 14351.257 param_var 34.442
1000/2000-(0.000): Train nll 14348.688 PPL inf agg_ckl 0.160 mi 0.000 zkl 0.001 dispersion 1.307 real_zkl 1.307 real_ckl 0.160 elbo 14350.155 param_var 11.829
1500/2000-(0.000): Train nll 14345.577 PPL inf agg_ckl 0.112 mi 0.000 zkl 0.000 dispersion 0.286 real_zkl 0.287 real_ckl 0.112 elbo 14345.976 param_var 2.992
2000/2000-(0.000): Train nll 14349.843 PPL inf agg_ckl 0.001 mi 0.000 zkl 0.000 dispersion 0.074 real_zkl 0.074 real_ckl 0.001 elbo 14349.918 param_var 0.562

=== Evaluating Model ===
Train nll 14347.621 PPL inf agg_ckl 0.146 mi 0.000 zkl 0.015 dispersion 1.544 real_zkl 1.559 real_ckl 0.146 elbo 14349.327 param_var 12.456
Valid nll 1780.483 PPL inf agg_ckl 0.001 mi 0.000 zkl 0.078 dispersion 0.005 real_zkl 0.083 real_ckl 0.001 elbo 1780.567 param_var 0.036
Total valid loss 1780.5674845377605
Generation: 1 batches
