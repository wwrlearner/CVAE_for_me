GMVAE (
  (x_encoder): EncoderRNN(
    (input_dropout): Dropout(p=0, inplace=False)
    (rnn): GRU(100, 64, batch_first=True, dropout=0.3, bidirectional=True)
  ), parameters=63744
  (decoder): DecoderRNN(
    (input_dropout): Dropout(p=0.3, inplace=False)
    (rnn): GRU(64, 64, batch_first=True, dropout=0.3)
    (project): Linear(in_features=64, out_features=2, bias=True)
  ), parameters=25090
  (q_y_mean): Linear(in_features=128, out_features=10, bias=True), parameters=1290
  (q_y_logvar): Linear(in_features=128, out_features=10, bias=True), parameters=1290
  (post_c): Sequential (
    (0): Linear(in_features=128, out_features=128, bias=True), weights=((128, 128), (128,)), parameters=16512
    (1): ReLU(), weights=(), parameters=0
    (2): Linear(in_features=128, out_features=40, bias=True), weights=((40, 128), (40,)), parameters=5160
  ) Total Parameters=21672, parameters=21672
  (dec_init_connector): LinearConnector(
    (linear): Linear(in_features=10, out_features=64, bias=False)
  ), parameters=640
  (firing_rate): Linear(in_features=2, out_features=100, bias=True), parameters=300
  (cat_connector): GumbelConnector(), parameters=0
  (mse_loss): TimeSeriesLossMSE(
    (mse_loss): MSELoss()
  ), parameters=0
  (cat_kl_loss): CatKLLoss(), parameters=0
) Total Parameters=114026
**** Training Begins ****
**** Epoch 0/50 ****
Flush previous valid loss
Recovering the learning rate to 0.001
Load previous best model
500/2000-(0.000): Train nll 14520.407 PPL inf agg_ckl 0.136 mi 0.001 zkl 0.053 dispersion 4.002 real_zkl 4.054 real_ckl 0.137 elbo 14524.599 param_var 20.904
1000/2000-(0.000): Train nll 14521.876 PPL inf agg_ckl 0.009 mi 0.000 zkl 0.000 dispersion 1.046 real_zkl 1.047 real_ckl 0.009 elbo 14522.931 param_var 3.558
1500/2000-(0.000): Train nll 14521.895 PPL inf agg_ckl 0.000 mi 0.000 zkl 0.000 dispersion 0.093 real_zkl 0.094 real_ckl 0.000 elbo 14521.989 param_var 0.334
2000/2000-(0.000): Train nll 14519.143 PPL inf agg_ckl 0.000 mi -0.000 zkl 0.000 dispersion 0.001 real_zkl 0.001 real_ckl 0.000 elbo 14519.144 param_var 0.006

=== Evaluating Model ===
Train nll 14520.830 PPL inf agg_ckl 0.036 mi 0.000 zkl 0.013 dispersion 1.286 real_zkl 1.299 real_ckl 0.037 elbo 14522.166 param_var 6.201
Valid nll 1803.611 PPL inf agg_ckl 0.000 mi 0.000 zkl 0.080 dispersion 0.000 real_zkl 0.080 real_ckl 0.001 elbo 1803.692 param_var 0.000
Total valid loss 1803.691874186198
Generation: 1 batches
