GMVAE (
  (x_encoder): EncoderRNN(
    (input_dropout): Dropout(p=0, inplace=False)
    (rnn): GRU(100, 64, batch_first=True, dropout=0.3, bidirectional=True)
  ), parameters=63744
  (decoder): DecoderRNN(
    (input_dropout): Dropout(p=0.3, inplace=False)
    (rnn): GRU(64, 64, batch_first=True, dropout=0.3)
    (project): Linear(in_features=64, out_features=2, bias=True)
  ), parameters=25090
  (q_y_mean): Linear(in_features=128, out_features=10, bias=True), parameters=1290
  (q_y_logvar): Linear(in_features=128, out_features=10, bias=True), parameters=1290
  (post_c): Sequential (
    (0): Linear(in_features=128, out_features=128, bias=True), weights=((128, 128), (128,)), parameters=16512
    (1): ReLU(), weights=(), parameters=0
    (2): Linear(in_features=128, out_features=40, bias=True), weights=((40, 128), (40,)), parameters=5160
  ) Total Parameters=21672, parameters=21672
  (dec_init_connector): LinearConnector(
    (linear): Linear(in_features=10, out_features=64, bias=False)
  ), parameters=640
  (firing_rate): Linear(in_features=2, out_features=100, bias=True), parameters=300
  (cat_connector): GumbelConnector(), parameters=0
  (mse_loss): TimeSeriesLossMSE(
    (mse_loss): MSELoss()
  ), parameters=0
  (cat_kl_loss): CatKLLoss(), parameters=0
) Total Parameters=114026
**** Training Begins ****
**** Epoch 0/50 ****
Flush previous valid loss
Recovering the learning rate to 0.001
Load previous best model
500/2000-(0.000): Train nll 14495.404 PPL inf agg_ckl 0.114 mi 0.001 zkl 0.078 dispersion 4.011 real_zkl 4.089 real_ckl 0.115 elbo 14499.609 param_var 68.918
1000/2000-(0.000): Train nll 14492.274 PPL inf agg_ckl 0.008 mi 0.000 zkl 0.001 dispersion 1.077 real_zkl 1.078 real_ckl 0.008 elbo 14493.360 param_var 22.288
1500/2000-(0.000): Train nll 14499.532 PPL inf agg_ckl 0.000 mi 0.000 zkl 0.001 dispersion 0.128 real_zkl 0.128 real_ckl 0.000 elbo 14499.660 param_var 3.551
2000/2000-(0.000): Train nll 14492.964 PPL inf agg_ckl 0.000 mi 0.000 zkl 0.000 dispersion 0.006 real_zkl 0.006 real_ckl 0.000 elbo 14492.971 param_var 0.267

=== Evaluating Model ===
Train nll 14495.044 PPL inf agg_ckl 0.031 mi 0.000 zkl 0.020 dispersion 1.305 real_zkl 1.325 real_ckl 0.031 elbo 14496.400 param_var 23.756
Valid nll 1810.822 PPL inf agg_ckl 0.001 mi 0.000 zkl 0.172 dispersion 0.000 real_zkl 0.172 real_ckl 0.001 elbo 1810.995 param_var 0.010
Total valid loss 1810.9953002929688
Generation: 1 batches
